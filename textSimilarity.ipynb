{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Similarity Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Computing similarity between two text pieces (terms/strings/documents/..)\n",
    "- Example Applications: \n",
    "    - Relevance of a document match for a query\n",
    "    - Computing semantic relatedness between strings/terms\n",
    "- Various measures available:\n",
    "    - Edit Distance/Levenshtein Distance\n",
    "    - Jaccard Distance\n",
    "    - Cosine Similarity\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Distance\n",
    "\n",
    "- Edit Distance (also known as Levenshtein Distance) between two strings is the minimum number of single character deletions, insertions, or substitutions required to transform one string into the other. \n",
    "- The edit distance between ”good” and ”goodbye” is 3.\n",
    "- Useful in spell checking applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating edit distance between two terms\n",
    "\n",
    "import nltk\n",
    " \n",
    "w1 = 'mapping'\n",
    "w2 = 'mappng'\n",
    " \n",
    "nltk.edit_distance(w1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating edit distance between two strings\n",
    "import nltk\n",
    " \n",
    "s1 = 'It might help to re-install Python if possible.'\n",
    "s2 = 'I possibly love Python programming.'\n",
    " \n",
    "nltk.edit_distance(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple 7\n",
      "bag 6\n",
      "drawing 4\n",
      "listing 1\n",
      "linking 2\n",
      "living 2\n",
      "lighting 1\n",
      "orange 6\n",
      "walking 4\n",
      "zoo 7\n"
     ]
    }
   ],
   "source": [
    "#finding the closest possible word from a list of words using edit distance\n",
    "import nltk\n",
    " \n",
    "mistake = \"ligting\"\n",
    " \n",
    "words = ['apple', 'bag', 'drawing', 'listing', 'linking', 'living', 'lighting', 'orange', 'walking', 'zoo']\n",
    " \n",
    "for word in words:\n",
    "    ed = nltk.edit_distance(mistake, word)\n",
    "    print(word, ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Distance\n",
    "\n",
    "- Measure of how dissimilar two sets of strings are. The lower the distance, the stringer the string similarity.\n",
    "- It is defined as the size of intersection divided by size of union of two sets. \n",
    "- Perform lemmatization first in order to increase the number of size of intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating jaccard distance between two terms\n",
    "\n",
    "import nltk\n",
    " \n",
    "w1 = set('mapping')\n",
    "w2 = set('mappng')\n",
    " \n",
    "nltk.jaccard_distance(w1, w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "\n",
    "Cosine similarity calculates similarity by measuring the cosine of angle between two vectors.\n",
    "- Sentences should, therefore, first be converted to vectors using BOW or TFIDF methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.34082422]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "documents=(\"AI is our friend and it has been friendly.\",\"AI and humans have always been friendly.\")\n",
    "\n",
    "tfidf_vectorizer=TfidfVectorizer()\n",
    "tfidf_matrix=tfidf_vectorizer.fit_transform(documents)\n",
    "#print(tfidf_matrix.toarray())\n",
    "\n",
    "cs=cosine_similarity(tfidf_matrix[0:1],tfidf_matrix)\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the results shows an array with the Cosine Similarities of the document 0 compared with other documents in the corpus. So, the first element in the array is 1 and it is the cosine similarity score of Document 0 with Document 0. The second element in the array, 0.3408, is the cosine similarity score between Document 0 and Document 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
